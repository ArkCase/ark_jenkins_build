#!/bin/bash

set -euo pipefail

ATTACHMENT_RESOURCE="volumeattachments.storage.k8s.io"

[ -v CLEANUP_TIMEOUT ] || CLEANUP_TIMEOUT=""
[ -n "${CLEANUP_TIMEOUT}" ] || CLEANUP_TIMEOUT="20m"

[ -v CLEANUP_RETRY_WAIT ] || CLEANUP_RETRY_WAIT=""
[ -n "${CLEANUP_RETRY_WAIT}" ] || CLEANUP_RETRY_WAIT="15s"

[ -v DISABLE_CLEANUP ] || DISABLE_CLEANUP=""
case "${DISABLE_CLEANUP,,}" in
	true | t | yes | y ) DISABLE_CLEANUP="true" ;;
	* ) DISABLE_CLEANUP="false" ;;
esac
export DISABLE_CLEANUP

timestamp()
{
	/usr/bin/date -Ins
}

say()
{
	echo -e "$(timestamp): ${@}"
}

ok()
{
	say "✅ ${@}"
}

warn()
{
	say "⚠️ ${@}"
}

err()
{
	say "❌ ${@}" 1>&2
}

fail()
{
	err "${@}"
	exit ${EXIT_CODE:-1}
}

is_valid_name()
{
	local NAME="${1}"
	[[ "${NAME}" =~ ^[a-z0-9]([-a-z0-9]*[a-z0-9])?$ ]] || return 1
	return 0
}

execute()
{
	#
	# Show the command about to be executed
	#
	say "${@@Q}"
	if "${DISABLE_CLEANUP}" ; then
		warn "Cleanup disabled: skipping the command execution"
		return 0
	fi

	#
	# Proceed with the execution
	#
	( exec "${@}" )
	return ${?}
}

#
# This function returns the number that serves as
# a multiplier/divisor for a given time scale
#
get_time_mul()
{
	local TAG="${1^^}"

	[[ "${TAG}" =~ ^[HDMS]$ ]] || return 1
	local DURATION_S=1
	local DURATION_M=$(( DURATION_S * 60 ))
	local DURATION_H=$(( DURATION_M * 60 ))
	local DURATION_D=$(( DURATION_H * 24 ))

	local VAR="DURATION_${TAG}"
	echo -n "${!VAR}"
}

#
# This function converts numbers of seconds into
# K8s timespecs, but leaves timespec strings alone
#
secs_to_timestr()
{
	local STR="${1}"
	local NUM="(0|[1-9][0-9]*)"

	[ -n "${STR}" ] || return 1

	# If it's already a time string, return it
	if [[ "${STR^^}" =~ ^(${NUM}D)?(${NUM}H)?(${NUM}M)?(${NUM}S)?$ ]] ; then
		echo -n "${STR,,}"
		return 0
	fi

	[[ "${STR}" =~ ^${NUM}$ ]] || return 1

	local RET=""
	local SIZE=0
	local MUL=0
	local SECS=${STR}
	for C in D H M S ; do
		MUL=$(get_time_mul "${C}")
		(( SIZE = ( SECS / MUL ) ))
		[ ${SIZE} -gt 0 ] && RET+="${SIZE}${C}"
		(( SECS -= ( SIZE * MUL ) ))
	done

	echo -n ${RET,,}
	return 0
}

#
# This function converts K8s timespecs into
# numbers of seconds, but leaves numbers alone
#
timestr_to_secs()
{
	local STR="${1}"
	local NUM="(0|[1-9][0-9]*)"

	# If it's a straight-up number,
	# seconds already, so just return it
	if [[ "${STR}" =~ ^${NUM}$ ]] ; then
		echo -e "${STR}"
		return 0
	fi

	# It could be a time string, so parse it out
	[ -n "${STR}" ] || return 1
	[[ "${STR^^}" =~ ^(${NUM}D)?(${NUM}H)?(${NUM}M)?(${NUM}S)?$ ]] || return 1

	local PARTS=( "${BASH_REMATCH[@]:1}" )
	[ ${#PARTS[@]} -ge 1 ] || return 1

	local SIZE=0
	local MUL=0
	local SECS=0
	for (( i = 0 ; i < ${#PARTS[@]} ; i++ )) ; do
		[[ "${PARTS[i]}" =~ ^${NUM}([DHMS])$ ]] || continue
		SIZE=${BASH_REMATCH[1]}
		MUL=$(get_time_mul "${BASH_REMATCH[2]}")
		(( SECS += SIZE * MUL ))
	done

	echo -n ${SECS}
	return 0
}

is_attachment_valid()
{
	local ATTACHMENT="${1}"
	local PVC_INFO="${2}"
	local PV_INFO="${3}"
	local ATTACHMENT_INFO="${4}"
	local NODE_INFO="${5}"

	local ATTACHED=""
	local NODE=""

	read ATTACHED NODE < <("${JQ}" -r '(.status.attached | tostring) + " " + .spec.nodeName' <<< "${ATTACHMENT_INFO}")
	if [ -z "${ATTACHED}" ] || [ -z "${NODE}" ] ; then
		# No node info?!?
		say "\t❌ the attachment [${ATTACHMENT}] has no node information... deleting"
		return 1
	fi

	if [ -z "${NODE_INFO}" ] ; then
		say "\t❌ ${ATTACHMENT} 🔗 ${NODE} is missing"
		return 1
	fi

	# Node is OK ... do we want to try to hunt down the pod that are using
	# its PVC? If those pods are down, perhaps this attachment can be deleted?
	say "\t✅ ${ATTACHMENT} 🔗 ${NODE}"
	return 0
}

dump_remaining()
{
	[ ${#} -eq 0 ] && return 0
	warn "The following ${#} attachments did not clear and may need manual intervention"
	for REC in "${@}" ; do
		IFS="/" read PVC PV ATTACHMENT NODE OK <<< "${REC}"
		"${OK}" && OK="✅" || OK="❌"
		say "\t${OK} ${PVC} 🔗 ${PV} 🔗 ${ATTACHMENT} 🔗 ${NODE}"
	done
	return 0
}

fail_for_timeout()
{
	say "⌛ Timed out waiting for the attachments to clear"
	dump_remaining "${@}"
}

usage()
{
	echo -e "usage: ${BASH_ARGV0:-${BASH_SOURCE:-${0}}} [namespace] release"
	exit 1
}

KUBECTL="$(type -P kubectl)" || fail "Could not find 'kubectl' in the path"
JQ="$(type -P jq)" || fail "Could not find 'jq' in the path"
SED="$(type -P sed)" || fail "Could not find 'sed' in the path"
SORT="$(type -P sort)" || fail "Could not find 'sort' in the path"
TIMEOUT="$(type -P timeout)" || fail "Could not find 'timeout' in the path"

[ ${#} -ge 1 ] && [ ${#} -le 2 ] || usage

CLEANUP_TIMEOUT=$(timestr_to_secs "${CLEANUP_TIMEOUT}") || fail "Invalid value for CLEANUP_TIMEOUT: [${CLEANUP_TIMEOUT}]"
CLEANUP_RETRY_WAIT=$(timestr_to_secs "${CLEANUP_RETRY_WAIT}") || fail "Invalid value for CLEANUP_RETRY_WAIT: [${CLEANUP_RETRY_WAIT}]"

if [ ${#} -eq 2 ] ; then
	NAMESPACE="${1}"
	shift
elif [ ! -v NAMESPACE ] ; then
	NAMESPACE="$("${KUBECTL}" config view --minify -o jsonpath="{..namespace}")"
	[ -n "${NAMESPACE}" ] || NAMESPACE="default"
fi
is_valid_name "${NAMESPACE}" || fail "The NAMESPACE value [${NAMESPACE}] is not valid"

RELEASE="${1}"
is_valid_name "${RELEASE}" || fail "The RELEASE value [${RELEASE}] is not valid"

"${KUBECTL}" get namespace "${NAMESPACE}" &>/dev/null || fail "The namespace [${NAMESPACE}] does not exist"

CLEANUP_TIMEOUT_STR="$(secs_to_timestr "${CLEANUP_TIMEOUT}")"
CLEANUP_RETRY_WAIT_STR="$(secs_to_timestr "${CLEANUP_RETRY_WAIT}")"
say "⌛ Waiting for the volume attachments to be released (up to ${CLEANUP_TIMEOUT_STR} total)..."
PREVIOUS_RUN=()
START="$(/usr/bin/date +%s)"
while true ; do

	# Get all the PVCs in the currently default namespace
	say "👀 Fetching all the PVC data on the namespace ${NAMESPACE} for release ${RELEASE}..."
	PVC_DATA="$("${KUBECTL}" get --namespace "${NAMESPACE}" pvc --selector="app.kubernetes.io/instance=${RELEASE}" -o json)"
	say "👀 Fetching all the PV data on cluster..."
	PV_DATA="$("${KUBECTL}" get pv -o json)"
	say "👀 Fetching all the Node data on the cluster..."
	NODE_DATA="$("${KUBECTL}" get node -o json)"

	PVC_COUNT="$("${JQ}" -r ".items | length" <<< "${PVC_DATA}")"

	ok "Found ${PVC_COUNT} PVCs"
	[ ${PVC_COUNT} -gt 0 ] || exit 0

	readarray -t PVCS < <("${JQ}" -r ".items[] | .metadata.name" <<< "${PVC_DATA}" | "${SORT}" -u)

	say "👀 Fetching all the Volume Attachment data on the cluster..."
	ATTACHMENT_DATA="$("${KUBECTL}" get "${ATTACHMENT_RESOURCE}" -o json)"

	(( BROKEN=0 )) || true
	CURRENT_RUN=()
	for PVC in "${PVCS[@]}" ; do

		PVC_INFO="$("${JQ}" -r ".items[] | select(.metadata.name == \"${PVC}\")" <<< "${PVC_DATA}")"

		PV="$("${JQ}" -r ".spec.volumeName" <<< "${PVC_INFO}")"
		PV_INFO="$("${JQ}" -r ".items[] | select(.metadata.name == \"${PV}\")" <<< "${PV_DATA}")"
		if [ -z "${PV}" ] || [ -z "${PV_INFO}" ] ; then
			err "No volume ${PV} found ... referenced by PVC ${PVC}"
			continue
		fi

		# For each PVC, identify the pod(s) it's attached to
		readarray -t ATTACHMENTS < <("${JQ}" -r ".items[] | select(.spec.source.persistentVolumeName == \"${PV}\") | .metadata.name" <<< "${ATTACHMENT_DATA}")

		[ "${#ATTACHMENTS[@]}" -gt 0 ] || continue

		say "👀 Found ${#ATTACHMENTS[@]} attachments for ${PVC}"
		for ATTACHMENT in "${ATTACHMENTS[@]}" ; do
			ATTACHMENT_INFO="$("${JQ}" -r ".items[] | select(.metadata.name == \"${ATTACHMENT}\")" <<< "${ATTACHMENT_DATA}")"
			NODE="$("${JQ}" -r '.spec.nodeName' <<< "${ATTACHMENT_INFO}")"

			NODE_INFO="$("${JQ}" -r ".items[] | select(.metadata.name == \"${NODE}\")" <<< "${NODE_DATA}")"

			ATTACHMENT_REF="${PVC}/${PV}/${ATTACHMENT}/${NODE}"
			OK="true"
			if ! is_attachment_valid "${ATTACHMENT}" "${PVC_INFO}" "${PV_INFO}" "${ATTACHMENT_INFO}" "${NODE_INFO}" ; then
				OK="false"
				(( ++BROKEN ))
			fi
			CURRENT_RUN+=("${ATTACHMENT_REF}/${OK}")
		done
	done

	if [ ${#CURRENT_RUN[@]} -eq ${BROKEN} ] ; then
		ok "All non-broken attachments have cleared!"
		dump_remaining "${CURRENT_RUN[@]}"
		exit 0
	fi

	say "👉 Found ${#CURRENT_RUN[@]} that are still pending removal (${BROKEN} appear to be broken)..."

	# There are still some ... have we timed out yet?
	NOW="$(/usr/bin/date +%s)"
	(( DIFF = ( NOW - START ) )) || true
	[ ${DIFF} -lt ${CLEANUP_TIMEOUT} ] || fail_for_timeout "${CURRENT_RUN[@]}"

	# Make sure our wait doesn't put us overbudget on the total wait
	# time period, and make sure that if we have to wait one last time,
	# that it also doesn't exceed our expected timeout
	(( REMAINING = CLEANUP_TIMEOUT - DIFF )) || true
	[ ${REMAINING} -gt 0 ] || fail_for_timeout "${CURRENT_RUN[@]}"
	if [ ${REMAINING} -lt ${CLEANUP_RETRY_WAIT} ] ; then
		# This will be our last wait, so just wait for however
		# long the timeout is remaining and try one last time
		CLEANUP_RETRY_WAIT=${REMAINING}
		CLEANUP_RETRY_WAIT_STR="$(secs_to_timestr "${CLEANUP_RETRY_WAIT}")"
	fi

	say "💤 Will wait ${CLEANUP_RETRY_WAIT_STR} before the next attempt..."
	/usr/bin/sleep ${CLEANUP_RETRY_WAIT} || fail "Sleep interrupted - cannot continue!"

done
exit 0
